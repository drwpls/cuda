{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGBgThS8q8k3"
      },
      "source": [
        "Họ tên: Phan Lộc Sơn\n",
        "\n",
        "MSSV: 19120033"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qdrvDrCrnqz"
      },
      "source": [
        "# HW4: Song song hóa Radix Sort"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKXB0wA7yhq9"
      },
      "source": [
        "Với các GPU tương đối mới thì để biên dịch chỉ cần dùng câu lệnh: \\\n",
        "`nvcc tên-file.cu -o tên-file-chạy`\n",
        "\n",
        "Nhưng trên Colab mình thường lấy được GPU khá cũ là Tesla K80 với compute capability (phiên bản phần cứng) là 3.7; để biên dịch đúng với GPU khá cũ này thì bạn cần dùng câu lệnh: \\\n",
        "`nvcc -arch=sm_37 tên-file.cu -o tên-file-chạy` \\\n",
        "Trong đó, 37 chính là compute capability của GPU Tesla K80.\n",
        "\n",
        "Để phòng trường hợp khi làm bài bạn lấy được GPU có compute capability x.x nhưng khi chấm bài Thầy lại lấy được GPU có compute capability khác x.x, dưới đây mình sẽ có đoạn code Python để tự động lấy 2 con số ứng với compute capability của GPU và lưu vào 2 biến `major` và `minor`:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCkmnirl2xWF",
        "outputId": "08b11907-fdf6-4164-8685-ec2b46ea3e23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from numba import cuda\n",
        "major, minor = cuda.get_current_device().compute_capability\n",
        "print(f'GPU compute capability: {major}.{minor}')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU compute capability: 7.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq1-pmi72yS6"
      },
      "source": [
        "Một khi đã chạy đoạn code Python ở trên, để biên dịch thì bạn sẽ dùng câu lệnh: \\\n",
        "`nvcc -arch=sm_{major}{minor} tên-file.cu -o tên-file-chạy`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xCyT0o8Z7nj"
      },
      "source": [
        "Dưới đây, khi làm bài thì bạn có thể tùy ý thêm/xóa cell. Đừng xóa mấy cell có chữ của Thầy là được."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbFLx1i4JxIE",
        "outputId": "3eea7ae9-ee14-4445-fbbb-ceedb9e43b58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvcc -arch=sm_{major}{minor} HW4.cu -o HW4"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**********GPU info**********\n",
            "Name: Tesla T4\n",
            "Compute capability: 7.5\n",
            "Num SMs: 40\n",
            "Max num threads per SM: 1024\n",
            "Max num warps per SM: 32\n",
            "GMEM: 15843721216 byte\n",
            "SMEM per SM: 65536 byte\n",
            "SMEM per block: 49152 byte\n",
            "****************************\n",
            "\n",
            "Input size: 16777217\n",
            "\n",
            "Radix Sort by host\n",
            "Time: 9345.183 ms\n",
            "\n",
            "Radix Sort by device\n",
            "Time: 9148.597 ms\n",
            "CORRECT :)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZNqZuECjNso",
        "outputId": "9811bde8-1d9a-4d59-b1fa-8121c3211de5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!./HW4 256"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**********GPU info**********\n",
            "Name: Tesla T4\n",
            "Compute capability: 7.5\n",
            "Num SMs: 40\n",
            "Max num threads per SM: 1024\n",
            "Max num warps per SM: 32\n",
            "GMEM: 15843721216 byte\n",
            "SMEM per SM: 65536 byte\n",
            "SMEM per block: 49152 byte\n",
            "****************************\n",
            "\n",
            "Input size: 16777217\n",
            "\n",
            "Radix Sort by host\n",
            "Time: 9224.513 ms\n",
            "\n",
            "Radix Sort by device\n",
            "Time: 10091.342 ms\n",
            "CORRECT :)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVFUj14OYUyy",
        "outputId": "9f5d6ecc-f8f6-4c4c-bbf1-a5dd62235186",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!./HW4 512"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**********GPU info**********\n",
            "Name: Tesla T4\n",
            "Compute capability: 7.5\n",
            "Num SMs: 40\n",
            "Max num threads per SM: 1024\n",
            "Max num warps per SM: 32\n",
            "GMEM: 15843721216 byte\n",
            "SMEM per SM: 65536 byte\n",
            "SMEM per block: 49152 byte\n",
            "****************************\n",
            "\n",
            "Input size: 16777217\n",
            "\n",
            "Radix Sort by host\n",
            "Time: 9225.333 ms\n",
            "\n",
            "Radix Sort by device\n",
            "Time: 9694.218 ms\n",
            "CORRECT :)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./HW4 1024"
      ],
      "metadata": {
        "id": "jluEYlcMM6Mr",
        "outputId": "6aac7c56-dc46-4901-cd2d-39b0a02e18a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**********GPU info**********\n",
            "Name: Tesla T4\n",
            "Compute capability: 7.5\n",
            "Num SMs: 40\n",
            "Max num threads per SM: 1024\n",
            "Max num warps per SM: 32\n",
            "GMEM: 15843721216 byte\n",
            "SMEM per SM: 65536 byte\n",
            "SMEM per block: 49152 byte\n",
            "****************************\n",
            "\n",
            "Input size: 16777217\n",
            "\n",
            "Radix Sort by host\n",
            "Time: 9307.771 ms\n",
            "\n",
            "Radix Sort by device\n",
            "Time: 8837.839 ms\n",
            "CORRECT :)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XebMjR45-0Io"
      },
      "source": [
        "Tốc độ của host ở cả 3 lần chạy gần như nhau.\n",
        "Tốc độ của kernel ở 3 lần chạy có cải thiện khi tăng blocksize lên.\n",
        "\n",
        "Sự cải thiện này có thể giải thích như sau:\n",
        "\n",
        "Ở mỗi lần scan, device scan cục bộ các block song song, sau đó, scan tổng của các biến thì lần lượt.\n",
        "\n",
        "- 1 block scan được nhiều phần tử, mà mỗi phần tử nằm trong shared_mem, nhanh -> giảm thời gian truy xuất\n",
        "\n",
        "- Giảm số phân tử trong aux array phải scan lần lượt, các phần tử này nằm ở global mem -> tăng tốc độ scan aux array.\n",
        "\n",
        "- Khi tăng blocksize: ví dụ từ 256 -> 512, ở reduce phase và Post-reduction phase, với 512 phần tử: 1 block 512 scan cục bộ mất 9 + 8 = 17 bước. 2 block 256 scan cục bộ hết 2x(8+7) = 30 bước. (nếu SM còn dư slot và 2 block này chạy song song thì chỉ mất 15 bước, nếu SM hết slot thì 2 block này chạy lần lượt thì mất 30 bước, do size trong mẫu chạy HW4.cu khá lớn nên coi như là SM luôn trong tình trạng hết slot). Ngoài ra 2 block 256 còn phải truy xuất global mem 2 lần để scan tổng aux."
      ]
    }
  ]
}