{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drwpls/cuda/blob/HW3/HW3/HW3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGBgThS8q8k3"
      },
      "source": [
        "Họ tên: Phan Lộc Sơn\n",
        "\n",
        "MSSV: 19120033"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qdrvDrCrnqz"
      },
      "source": [
        "# HW3: Các loại bộ nhớ trong CUDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKXB0wA7yhq9"
      },
      "source": [
        "Với các GPU tương đối mới thì để biên dịch chỉ cần dùng câu lệnh: \\\n",
        "`nvcc tên-file.cu -o tên-file-chạy`\n",
        "\n",
        "Nhưng trên Colab mình thường lấy được GPU khá cũ là Tesla K80 với compute capability (phiên bản phần cứng) là 3.7; để biên dịch đúng với GPU khá cũ này thì bạn cần dùng câu lệnh: \\\n",
        "`nvcc -arch=sm_37 tên-file.cu -o tên-file-chạy` \\\n",
        "Trong đó, 37 chính là compute capability của GPU Tesla K80.\n",
        "\n",
        "Để phòng trường hợp khi làm bài bạn lấy được GPU có compute capability x.x nhưng khi chấm bài Thầy lại lấy được GPU có compute capability khác x.x, dưới đây mình sẽ có đoạn code Python để tự động lấy 2 con số ứng với compute capability của GPU và lưu vào 2 biến `major` và `minor`:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCkmnirl2xWF",
        "outputId": "4873e5f9-c796-4e7e-e008-cdae9650d617",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from numba import cuda\n",
        "major, minor = cuda.get_current_device().compute_capability\n",
        "print(f'GPU compute capability: {major}.{minor}')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU compute capability: 7.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq1-pmi72yS6"
      },
      "source": [
        "Một khi đã chạy đoạn code Python ở trên, để biên dịch thì bạn sẽ dùng câu lệnh: \\\n",
        "`nvcc -arch=sm_{major}{minor} tên-file.cu -o tên-file-chạy`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xCyT0o8Z7nj"
      },
      "source": [
        "Dưới đây, khi làm bài thì bạn có thể tùy ý thêm/xóa cell. Đừng xóa mấy cell có chữ của Thầy là được."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fetch code from github"
      ],
      "metadata": {
        "id": "MvK7e6jUo012"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbFLx1i4JxIE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cbad8dc-647a-408e-a12d-4a13f50040bf"
      },
      "source": [
        "%cd /content\n",
        "!rm -rf cuda\n",
        "!git clone -b HW3 https://github.com/drwpls/cuda.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'cuda'...\n",
            "remote: Enumerating objects: 114, done.\u001b[K\n",
            "remote: Counting objects: 100% (114/114), done.\u001b[K\n",
            "remote: Compressing objects: 100% (101/101), done.\u001b[K\n",
            "remote: Total 114 (delta 41), reused 52 (delta 11), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (114/114), 1.77 MiB | 11.09 MiB/s, done.\n",
            "Resolving deltas: 100% (41/41), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change working directory to HW3 folder:"
      ],
      "metadata": {
        "id": "5naeXQtzpB1U"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZNqZuECjNso",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c55127f6-928d-4b6e-c5cf-4d44aea37876"
      },
      "source": [
        "%cd ./cuda/HW3"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cuda/HW3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can verify by run `pwd`"
      ],
      "metadata": {
        "id": "yjsLFCUSpJXs"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVFUj14OYUyy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91be2a8b-7566-4c19-a070-391282b313fe"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cuda/HW3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XebMjR45-0Io"
      },
      "source": [
        "Compile HW3 binary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_{major}{minor} HW3.cu -o HW3 "
      ],
      "metadata": {
        "id": "0npp22M_pVCB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the binary"
      ],
      "metadata": {
        "id": "5xKrhEpOpink"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./HW3 in.pnm out.pnm 16 16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnQ6AnaDpjFM",
        "outputId": "f751faeb-d79d-4ff3-b7cb-27b23fd07bef"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**********GPU info**********\n",
            "Name: Tesla T4\n",
            "Compute capability: 7.5\n",
            "Num SMs: 40\n",
            "Max num threads per SM: 1024\n",
            "Max num warps per SM: 32\n",
            "GMEM: 15843721216 bytes\n",
            "CMEM: 65536 bytes\n",
            "L2 cache: 4194304 bytes\n",
            "SMEM / one SM: 65536 bytes\n",
            "****************************\n",
            "\n",
            "Image size (width x height): 512 x 512\n",
            "\n",
            "Kernel 1, block size 16x16, grid size 32x32\n",
            "Kernel time: 0.468992 ms\n",
            "Error: 0.000703\n",
            "\n",
            "Kernel 2, block size 16x16, grid size 32x32\n",
            "Kernel time: 0.305920 ms\n",
            "Error: 0.000703\n",
            "\n",
            "Kernel 3, block size 16x16, grid size 32x32\n",
            "Kernel time: 0.233504 ms\n",
            "Error: 0.000703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./HW3 in.pnm out.pnm 32 32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJthznoFzlxQ",
        "outputId": "b4a8dc0c-dd55-4dc8-bdaf-0ebf4719c930"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**********GPU info**********\n",
            "Name: Tesla T4\n",
            "Compute capability: 7.5\n",
            "Num SMs: 40\n",
            "Max num threads per SM: 1024\n",
            "Max num warps per SM: 32\n",
            "GMEM: 15843721216 bytes\n",
            "CMEM: 65536 bytes\n",
            "L2 cache: 4194304 bytes\n",
            "SMEM / one SM: 65536 bytes\n",
            "****************************\n",
            "\n",
            "Image size (width x height): 512 x 512\n",
            "\n",
            "Kernel 1, block size 32x32, grid size 16x16\n",
            "Kernel time: 0.346112 ms\n",
            "Error: 0.000703\n",
            "\n",
            "Kernel 2, block size 32x32, grid size 16x16\n",
            "Kernel time: 0.339968 ms\n",
            "Error: 0.000703\n",
            "\n",
            "Kernel 3, block size 32x32, grid size 16x16\n",
            "Kernel time: 0.262304 ms\n",
            "Error: 0.000703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nhận xét: Cơ bản, hàm Kernel 3 chạy nhanh hơn Kernel 2 và Kernel 2 chạy nhanh hơn Kernel 1.\n",
        "\n",
        "- Hàm kernel 2 chạy nhanh hơn kernel 1 vì: \n",
        " + Dùng shared memory để load vào trước rồi mới tính toán. Thay vì mỗi lần tinh là một lần load data từ global memory vao thì kernel2 load vào shared_memory hết rồi mới tính.\n",
        " + Khi block size = 16 x 16, hàm kernel 2 nhanh hơn hẳn kernel 1 vì: Trong 1 block, có ít threads hơn -> khi các threads chạy và load từ global mem sang shared mem, ít memory transaction bị bank conflict hơn -> tận dụng shared memory tố hơn.\n",
        "\n",
        "- Hàm kernel 3 chạy hơn hơn kernel 2 vì nó load filter data từ bộ nhớ constant nằm ở layer thấp hơn so với load trực tiêp từ gloabal memory (mỗi threads ở kernel 2 và kernel 1 phải load toàn bộ filter vào: filterWidth^2 phần tử)"
      ],
      "metadata": {
        "id": "PpXTDirb2Pp0"
      }
    }
  ]
}